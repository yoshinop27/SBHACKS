---
title: Getting Started
subtitle: >-
  An introduction to using Deepgram's Voice Agent API to build interactive voice
  agents.
slug: docs/voice-agent
---

<Card
    href="https://playground.deepgram.com/?endpoint=agent"
>
  <div class="t-default text-base font-semibold">Deepgram API Playground</div>
  Try this feature out in our API Playground.
</Card>
<br/>

In this guide, you'll learn how to create a very basic voice agent using Deepgram's Agent API. Visit the [API Reference](/reference/voice-agent/voice-agent) for more details on how to use the Agent API.

<Warning>
You will need to migrate to the new ***Voice Agent API V1*** to continue to use the Voice Agent API. Please refer to the [Voice Agent API Migration Guide](/docs/voice-agent-v1-migration) for more information.
</Warning>

## Build a Basic Voice Agent

<Info>
  Before you start, you'll need to follow the steps in the [Make Your First API Request](/guides/fundamentals/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.
</Info>

### 1. Set up your environment

In the steps below, you'll use the Terminal to:

1. Create a new directory for your project
2. Create a new file for your code
3. Export your Deepgram API key to the environment so you can use it in your code
4. Run any additional commands to initialize your project

<CodeGroup>
  ```shell Python
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.py
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"
  ```

  ```shell JavaScript
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.js
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"
npm init -y
  ```

  ```shell C#
# for MacOS
mkdir deepgram-agent-demo
cd deepgram-agent-demo
dotnet new console
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"

# for Windows Powershell
mkdir deepgram-agent-demo
cd deepgram-agent-demo
dotnet new console
$env:DEEPGRAM_API_KEY = "your_Deepgram_API_key_here"
  ```

  ```shell Go
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.go
go mod tidy
  ```
</CodeGroup>

### 2. Install the Deepgram SDK

Deepgram has several [SDKs](/home) that can make it easier to build a Voice Agent. Follow these steps below to use one of our SDKs to make your first Deepgram Voice Agent request.

In your terminal, navigate to the location on your drive where you created your project above, and install the Deepgram SDK and any other dependencies.

<CodeGroup>
  ```shell Python
  pip install deepgram-sdk
  ```

  ```shell JavaScript
  npm install @deepgram/sdk cross-fetch
  - or -
  yarn add @deepgram/sdk cross-fetch
  ```

  ```shell C#
  dotnet add package Deepgram
  ```

  ```shell Go
  go get github.com/deepgram/deepgram-go-sdk
  ```
</CodeGroup>

### 3. Import dependencies and set up the main function

Next, import the necessary dependencies and set up your main application function.

<CodeGroup>
  ```python Python
  # For help migrating to the new Python SDK, check out our migration guide:
  # https://github.com/deepgram/deepgram-python-sdk/blob/main/docs/Migrating-v3-to-v5.md

  # Import dependencies and set up the main function
  import requests
  import wave
  import io
  import time
  import os
  import json
  import threading
  from datetime import datetime

  from deepgram import DeepgramClient
  from deepgram.core.events import EventType
  from deepgram.extensions.types.sockets import (
      AgentV1Agent,
      AgentV1AudioConfig,
      AgentV1AudioInput,
      AgentV1AudioOutput,
      AgentV1DeepgramSpeakProvider,
      AgentV1Listen,
      AgentV1ListenProvider,
      AgentV1OpenAiThinkProvider,
      AgentV1SettingsMessage,
      AgentV1SocketClientResponse,
      AgentV1SpeakProviderConfig,
      AgentV1Think,
  )
  ```

  ```javascript JavaScript
  const { createClient, AgentEvents } = require("@deepgram/sdk");
  const { writeFile, appendFile } = require("fs/promises");
  const fetch = require("cross-fetch");
  const { join } = require("path");

  const agent = async () => {
      // The code in the following steps will go here
  };

  void agent();
  ```
  ```csharp C#
using Deepgram.Logger;
using Deepgram.Models.Authenticate.v1;
using Deepgram.Models.Agent.v2.WebSocket;
using System.Collections.Generic;
using System.Net.Http;

namespace SampleApp
{
    class Program
    {
        static async Task Main(string[] args)
        {
            try
            {
              // The code in the following steps will go here

  ```
  ```go Go
// Copyright 2024 Deepgram SDK contributors. All Rights Reserved.
// Use of this source code is governed by a MIT license that can be found in the LICENSE file.
// SPDX-License-Identifier: MIT

package main

// Import dependencies
import (
	"bufio"
	"context"
	"fmt"
	"io"
	"net/http"
	"os"
	"reflect"
	"runtime/debug"
	"strings"
	"sync"
	"time"

	msginterfaces "github.com/deepgram/deepgram-go-sdk/pkg/api/agent/v1/websocket/interfaces"
	client "github.com/deepgram/deepgram-go-sdk/pkg/client/agent"
	"github.com/deepgram/deepgram-go-sdk/pkg/client/interfaces"
)
// The code in the following steps will go here
  ```
</CodeGroup>

### 4. Initialize the Voice Agent

Now you can initialize the voice agent by creating an empty audio buffer to store incoming audio data, setting up a counter for output file naming, and defining a sample audio file URL. You can then establish a connection to Deepgram and set up a welcome handler to log when the connection is successfully established.

<CodeGroup>
  ```python Python
  # For help migrating to the new Python SDK, check out our migration guide:
  # https://github.com/deepgram/deepgram-python-sdk/blob/main/docs/Migrating-v3-to-v5.md

  def main():
    try:
        # Initialize the Voice Agent
        api_key = os.getenv("DEEPGRAM_API_KEY")
        if not api_key:
            raise ValueError("DEEPGRAM_API_KEY environment variable is not set")
        print("API Key found")

        # Initialize Deepgram client
        client = DeepgramClient(api_key=api_key)

        # Use connection as a context manager
        with client.agent.v1.connect() as connection:
            print("Created WebSocket connection...")

            # The code in the following steps will go here
  ```
  ```javascript JavaScript
  let audioBuffer = Buffer.alloc(0);
  let i = 0;
  const url = "https://dpgr.am/spacewalk.wav";
  const connection = deepgram.agent();
  connection.on(AgentEvents.Welcome, () => {
    console.log("Welcome to the Deepgram Voice Agent!");
    // The code in the following steps will go here
  });

  ```
  ```csharp C#
  // Initialize Library with default logging
                // Normal logging is "Info" level
                Deepgram.Library.Initialize(LogLevel.Debug);
                // OR very chatty logging
                //Deepgram.Library.Initialize(LogLevel.Verbose); // LogLevel.Default, LogLevel.Debug, LogLevel.Verbose

                Console.WriteLine("\n\nPress any key to stop and exit...\n\n\n");

                // Set "DEEPGRAM_API_KEY" environment variable to your Deepgram API Key
                DeepgramWsClientOptions options = new DeepgramWsClientOptions(null, null, true);
                var agentClient = ClientFactory.CreateAgentWebSocketClient(apiKey: "", options: options);

                // current time
                var lastAudioTime = DateTime.Now;
                var audioFileCount = 0;
  ```
  ```go Go
// Initialize the Voice Agent
type MyHandler struct {
	binaryChan                   chan *[]byte
	openChan                     chan *msginterfaces.OpenResponse
	welcomeResponse              chan *msginterfaces.WelcomeResponse
	conversationTextResponse     chan *msginterfaces.ConversationTextResponse
	userStartedSpeakingResponse  chan *msginterfaces.UserStartedSpeakingResponse
	agentThinkingResponse        chan *msginterfaces.AgentThinkingResponse
	agentStartedSpeakingResponse chan *msginterfaces.AgentStartedSpeakingResponse
	agentAudioDoneResponse       chan *msginterfaces.AgentAudioDoneResponse
	closeChan                    chan *msginterfaces.CloseResponse
	errorChan                    chan *msginterfaces.ErrorResponse
	unhandledChan                chan *[]byte
	injectionRefusedResponse     chan *msginterfaces.InjectionRefusedResponse
	keepAliveResponse            chan *msginterfaces.KeepAlive
	settingsAppliedResponse      chan *msginterfaces.SettingsAppliedResponse
	functionCallRequestResponse  chan *msginterfaces.FunctionCallRequestResponse
	chatLogFile                  *os.File
}

// Channel getter methods to implement AgentMessageChan interface
func (dch MyHandler) GetBinary() []*chan *[]byte {
	return []*chan *[]byte{&dch.binaryChan}
}

func (dch MyHandler) GetOpen() []*chan *msginterfaces.OpenResponse {
	return []*chan *msginterfaces.OpenResponse{&dch.openChan}
}

func (dch MyHandler) GetWelcome() []*chan *msginterfaces.WelcomeResponse {
	return []*chan *msginterfaces.WelcomeResponse{&dch.welcomeResponse}
}

func (dch MyHandler) GetConversationText() []*chan *msginterfaces.ConversationTextResponse {
	return []*chan *msginterfaces.ConversationTextResponse{&dch.conversationTextResponse}
}

func (dch MyHandler) GetUserStartedSpeaking() []*chan *msginterfaces.UserStartedSpeakingResponse {
	return []*chan *msginterfaces.UserStartedSpeakingResponse{&dch.userStartedSpeakingResponse}
}

func (dch MyHandler) GetAgentThinking() []*chan *msginterfaces.AgentThinkingResponse {
	return []*chan *msginterfaces.AgentThinkingResponse{&dch.agentThinkingResponse}
}

func (dch MyHandler) GetAgentStartedSpeaking() []*chan *msginterfaces.AgentStartedSpeakingResponse {
	return []*chan *msginterfaces.AgentStartedSpeakingResponse{&dch.agentStartedSpeakingResponse}
}

func (dch MyHandler) GetAgentAudioDone() []*chan *msginterfaces.AgentAudioDoneResponse {
	return []*chan *msginterfaces.AgentAudioDoneResponse{&dch.agentAudioDoneResponse}
}

func (dch MyHandler) GetClose() []*chan *msginterfaces.CloseResponse {
	return []*chan *msginterfaces.CloseResponse{&dch.closeChan}
}

func (dch MyHandler) GetError() []*chan *msginterfaces.ErrorResponse {
	return []*chan *msginterfaces.ErrorResponse{&dch.errorChan}
}

func (dch MyHandler) GetUnhandled() []*chan *[]byte {
	return []*chan *[]byte{&dch.unhandledChan}
}

func (dch MyHandler) GetInjectionRefused() []*chan *msginterfaces.InjectionRefusedResponse {
	return []*chan *msginterfaces.InjectionRefusedResponse{&dch.injectionRefusedResponse}
}

func (dch MyHandler) GetKeepAlive() []*chan *msginterfaces.KeepAlive {
	return []*chan *msginterfaces.KeepAlive{&dch.keepAliveResponse}
}

func (dch MyHandler) GetFunctionCallRequest() []*chan *msginterfaces.FunctionCallRequestResponse {
	return []*chan *msginterfaces.FunctionCallRequestResponse{&dch.functionCallRequestResponse}
}

func (dch MyHandler) GetSettingsApplied() []*chan *msginterfaces.SettingsAppliedResponse {
	return []*chan *msginterfaces.SettingsAppliedResponse{&dch.settingsAppliedResponse}
}

// Initialize the Voice Agent
func NewMyHandler() *MyHandler {
	// Create chat log file
	chatLogFile, err := os.OpenFile("chatlog.txt", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil {
		fmt.Printf("Failed to create chat log file: %v\n", err)
		return nil
	}

	handler := &MyHandler{
		binaryChan:                   make(chan *[]byte),
		openChan:                     make(chan *msginterfaces.OpenResponse),
		welcomeResponse:              make(chan *msginterfaces.WelcomeResponse),
		conversationTextResponse:     make(chan *msginterfaces.ConversationTextResponse),
		userStartedSpeakingResponse:  make(chan *msginterfaces.UserStartedSpeakingResponse),
		agentThinkingResponse:        make(chan *msginterfaces.AgentThinkingResponse),
		agentStartedSpeakingResponse: make(chan *msginterfaces.AgentStartedSpeakingResponse),
		agentAudioDoneResponse:       make(chan *msginterfaces.AgentAudioDoneResponse),
		closeChan:                    make(chan *msginterfaces.CloseResponse),
		errorChan:                    make(chan *msginterfaces.ErrorResponse),
		unhandledChan:                make(chan *[]byte),
		injectionRefusedResponse:     make(chan *msginterfaces.InjectionRefusedResponse),
		keepAliveResponse:            make(chan *msginterfaces.KeepAlive),
		settingsAppliedResponse:      make(chan *msginterfaces.SettingsAppliedResponse),
		functionCallRequestResponse:  make(chan *msginterfaces.FunctionCallRequestResponse),
		chatLogFile:                  chatLogFile,
	}

	go func() {
		handler.Run()
	}()

	return handler
}
// The code in the following steps will go here
  };
  ```
</CodeGroup>

### 5. Configure the Agent

Next you will need to set up a very simplified version of the [Settings](/docs/voice-agent-settings) message to configure your Agent's behavior and set the required settings options for your Agent.

<Info>
  To learn more about all settings options available for an Agent, refer to the [Configure the Voice Agent](/docs/configure-voice-agent) documentation.
</Info>

<CodeGroup>
  ```python Python
    # Configure the Agent
            settings = AgentV1SettingsMessage(
                audio=AgentV1AudioConfig(
                    input=AgentV1AudioInput(
                        encoding="linear16",
                        sample_rate=24000,
                    ),
                    output=AgentV1AudioOutput(
                        encoding="linear16",
                        sample_rate=24000,
                        container="wav",
                    ),
                ),
                agent=AgentV1Agent(
                    language="en",
                    listen=AgentV1Listen(
                        provider=AgentV1ListenProvider(
                            type="deepgram",
                            model="nova-3",
                        )
                    ),
                    think=AgentV1Think(
                        provider=AgentV1OpenAiThinkProvider(
                            type="open_ai",
                            model="gpt-4o-mini",
                        ),
                        prompt="You are a friendly AI assistant.",
                    ),
                    speak=AgentV1SpeakProviderConfig(
                        provider=AgentV1DeepgramSpeakProvider(
                            type="deepgram",
                            model="aura-2-thalia-en",
                        )
                    ),
                    greeting="Hello! How can I help you today?",
                ),
            )
  ```

  ```javascript JavaScript
connection.configure({
      audio: {
        input: {
          encoding: "linear16",
          sample_rate: 24000,
        },
        output: {
          encoding: "linear16",
          sample_rate: 16000,
          container: "wav",
        },
      },
      agent: {
        language: "en",
        listen: {
          provider: {
            type: "deepgram",
            model: "nova-3",
          },
        },
        think: {
          provider: {
            type: "open_ai",
            model: "gpt-4o-mini",
          },
          prompt: "You are a friendly AI assistant.",
        },
        speak: {
          provider: {
            type: "deepgram",
            model: "aura-2-thalia-en",
          },
        },
        greeting: "Hello! How can I help you today?",
      },
    });

    console.log("Deepgram agent configured!");
  ```

  ```csharp C#
       // Start the connection
                var settingsConfiguration = new SettingsSchema();
                settingsConfiguration.Agent.Think.Provider.Type = "open_ai";
                settingsConfiguration.Agent.Think.Provider.Model = "gpt-4o-mini";
                settingsConfiguration.Audio.Output.SampleRate = 24000;
                settingsConfiguration.Audio.Output.Container = "wav";
                settingsConfiguration.Audio.Input.SampleRate = 24000;
                settingsConfiguration.Agent.Greeting = "Hello, how can I help you today?";
                settingsConfiguration.Agent.Listen.Provider.Model = "nova-3";
                settingsConfiguration.Agent.Listen.Provider.Keyterms = new List<string> { "Deepgram" };
                settingsConfiguration.Agent.Speak.Provider.Type = "deepgram";
                settingsConfiguration.Agent.Speak.Provider.Model = "aura-2-thalia-en";

                // To avoid issues with empty objects, Voice and Endpoint are instantiated as null. Construct them as needed.
                // settingsConfiguration.Agent.Speak.Provider.Voice = new CartesiaVoice();
                // settingsConfiguration.Agent.Speak.Provider.Voice.Id = "en-US-Wavenet-D";
                // settingsConfiguration.Agent.Speak.Endpoint = new Endpoint();
                // settingsConfiguration.Agent.Think.Endpoint = new Endpoint();

                bool bConnected = await agentClient.Connect(settingsConfiguration);
                if (!bConnected)
                {
                    Console.WriteLine("Failed to connect to Deepgram WebSocket server.");
                    return;
                }
  ```

  ```go Go
// Configure the Agent
func configureAgent() *interfaces.ClientOptions {
	// Initialize library
	client.Init(client.InitLib{
		LogLevel: client.LogLevelVerbose,
	})
  // The code in the following steps will go here
  };


  ```
</CodeGroup>

### 6. Send Keep Alive messages

Next you will send a keep-alive signal every 5 seconds to maintain the WebSocket connection. This prevents the connection from timing out during long audio processing. You will also fetch an audio file from the specified URL [spacewalk.wav](https://dpgr.am/spacewalk.wav) and stream the audio data in chunks to the Agent. Each chunk is sent as it becomes available in the readable stream.

<CodeGroup>
  ```python Python
      # Send settings to configure the agent
            print("Sending settings configuration...")
            connection.send_settings(settings)
            print("Settings sent successfully")

  ```
  ```javascript JavaScript

setInterval(() => {
      console.log("Keep alive!");
      connection.keepAlive();
    }, 5000);

    fetch(url)
      .then((r) => r.body)
      .then((res) => {
        res.on("readable", () => {
          console.log("Sending audio chunk");
          connection.send(res.read());
        });
      });
  ```
  ```csharp C#
  N/A
  ```
  ```go Go
  // Set client keep alive options
	return &interfaces.ClientOptions{
		EnableKeepAlive: true,
	}
}
```
</CodeGroup>

### 7. Setup Event Handlers and Other Functions

Next you will use this code to set up event handlers for the voice agent to manage the entire conversation lifecycle, from connection opening to closing. It handles audio processing by collecting chunks into a buffer and saving completed responses as WAV files, while also managing interruptions, logging conversations, and handling errors.

<CodeGroup>
  ```python Python
         # Setup Event Handlers
            audio_buffer = bytearray()
            file_counter = 0
            processing_complete = False

            def on_open(event):
                print("Connection opened")

            def on_message(message: AgentV1SocketClientResponse):
                nonlocal audio_buffer, file_counter, processing_complete

                # Handle binary audio data
                if isinstance(message, bytes):
                    audio_buffer.extend(message)
                    print(f"Received audio data: {len(message)} bytes")
                    return

                # Handle different message types
                msg_type = getattr(message, "type", "Unknown")
                print(f"Received {msg_type} event")

                # Handle specific event types
                if msg_type == "Welcome":
                    print(f"Welcome: {message}")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"Welcome: {message}\n")

                elif msg_type == "SettingsApplied":
                    print(f"Settings applied: {message}")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"Settings applied: {message}\n")

                elif msg_type == "ConversationText":
                    print(f"Conversation: {message}")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"{json.dumps(message.__dict__)}\n")

                elif msg_type == "UserStartedSpeaking":
                    print(f"User started speaking")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"User started speaking\n")

                elif msg_type == "AgentThinking":
                    print(f"Agent thinking")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"Agent thinking\n")

                elif msg_type == "AgentStartedSpeaking":
                    audio_buffer = bytearray()  # Reset buffer for new response
                    print(f"Agent started speaking")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"Agent started speaking\n")

                elif msg_type == "AgentAudioDone":
                    print(f"Agent audio done")
                    if len(audio_buffer) > 0:
                        with open(f"output-{file_counter}.wav", 'wb') as f:
                            f.write(create_wav_header())
                            f.write(audio_buffer)
                        print(f"Created output-{file_counter}.wav")
                    audio_buffer = bytearray()
                    file_counter += 1
                    processing_complete = True

            def on_error(error):
                print(f"Error: {error}")
                with open("chatlog.txt", 'a') as chatlog:
                    chatlog.write(f"Error: {error}\n")

            def on_close(event):
                print(f"Connection closed")
                with open("chatlog.txt", 'a') as chatlog:
                    chatlog.write(f"Connection closed\n")

            # Register event handlers
            connection.on(EventType.OPEN, on_open)
            connection.on(EventType.MESSAGE, on_message)
            connection.on(EventType.ERROR, on_error)
            connection.on(EventType.CLOSE, on_close)
            print("Event handlers registered")

            # Send settings to configure the agent
            print("Sending settings configuration...")
            connection.send_settings(settings)
            print("Settings sent successfully")

            # Start listening for events in a background thread
            print("Starting event listener...")
            listener_thread = threading.Thread(target=connection.start_listening, daemon=True)
            listener_thread.start()

            # Wait a moment for connection to establish
            time.sleep(1)

            # Stream audio
            print("Downloading and sending audio...")
            response = requests.get("https://dpgr.am/spacewalk.wav", stream=True)
            # Skip WAV header
            header = response.raw.read(44)

            # Verify WAV header
            if header[0:4] != b'RIFF' or header[8:12] != b'WAVE':
                print("Invalid WAV header")
                return

            chunk_size = 8192
            total_bytes_sent = 0
            chunk_count = 0
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:
                    print(f"Sending chunk {chunk_count}: {len(chunk)} bytes")
                    connection.send_media(chunk)
                    total_bytes_sent += len(chunk)
                    chunk_count += 1
                    time.sleep(0.1)  # Small delay between chunks

            print(f"Total audio data sent: {total_bytes_sent} bytes in {chunk_count} chunks")
            print("Waiting for agent response...")

            # Wait for processing
            print("Waiting for processing to complete...")
            start_time = time.time()
            timeout = 30  # 30 second timeout

            while not processing_complete and (time.time() - start_time) < timeout:
                time.sleep(1)
                print(f"Still waiting for agent response... ({int(time.time() - start_time)}s elapsed)")

            if not processing_complete:
                print("Processing timed out after 30 seconds")
            else:
                print("Processing complete. Check output-*.wav and chatlog.txt for results.")

            print("Finished")

    except Exception as e:
        print(f"Error: {str(e)}")

# WAV Header Functions
def create_wav_header(sample_rate=24000, bits_per_sample=16, channels=1):
    """Create a WAV header with the specified parameters"""
    byte_rate = sample_rate * channels * (bits_per_sample // 8)
    block_align = channels * (bits_per_sample // 8)

    header = bytearray(44)
    # RIFF header
    header[0:4] = b'RIFF'
    header[4:8] = b'\x00\x00\x00\x00'  # File size (to be updated later)
    header[8:12] = b'WAVE'
    # fmt chunk
    header[12:16] = b'fmt '
    header[16:20] = b'\x10\x00\x00\x00'  # Subchunk1Size (16 for PCM)
    header[20:22] = b'\x01\x00'  # AudioFormat (1 for PCM)
    header[22:24] = channels.to_bytes(2, 'little')  # NumChannels
    header[24:28] = sample_rate.to_bytes(4, 'little')  # SampleRate
    header[28:32] = byte_rate.to_bytes(4, 'little')  # ByteRate
    header[32:34] = block_align.to_bytes(2, 'little')  # BlockAlign
    header[34:36] = bits_per_sample.to_bytes(2, 'little')  # BitsPerSample
    # data chunk
    header[36:40] = b'data'
    header[40:44] = b'\x00\x00\x00\x00'  # Subchunk2Size (to be updated later)

    return header

if __name__ == "__main__":
    main()
  ```
  ```javascript JavaScript

  connection.on(AgentEvents.Open, () => {
    console.log("Connection opened");
  });

  connection.on(AgentEvents.Close, () => {
    console.log("Connection closed");
    process.exit(0);
  });

  connection.on(AgentEvents.ConversationText, async (data) => {
    await appendFile(join(__dirname, `chatlog.txt`), JSON.stringify(data) + "\n");
  });

  connection.on(AgentEvents.UserStartedSpeaking, () => {
    if (audioBuffer.length) {
      console.log("Interrupting agent.");
      audioBuffer = Buffer.alloc(0);
    }
  });

  connection.on(AgentEvents.Metadata, (data) => {
    console.dir(data, { depth: null });
  });

  connection.on(AgentEvents.Audio, (data) => {
    console.log("Audio chunk received");
    // Concatenate the audio chunks into a single buffer
    const buffer = Buffer.from(data);
    audioBuffer = Buffer.concat([audioBuffer, buffer]);
  });

  connection.on(AgentEvents.Error, (err) => {
    console.error("Error!");
    console.error(JSON.stringify(err, null, 2));
    console.error(err.message);
  });

  connection.on(AgentEvents.AgentAudioDone, async () => {
    console.log("Agent audio done");
    await writeFile(join(__dirname, `output-${i}.wav`), audioBuffer);
    audioBuffer = Buffer.alloc(0);
    i++;
  });

  connection.on(AgentEvents.Unhandled, (data) => {
    console.dir(data, { depth: null });
  });
};

  ```
  ```csharp C#
  // Subscribe to the EventResponseReceived event
                var subscribeResult = await agentClient.Subscribe(new EventHandler<OpenResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e.Type} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to OpenResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AudioResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e.Type} received");

                    // if the last audio response is more than 5 seconds ago, add a wav header
                    if (DateTime.Now.Subtract(lastAudioTime).TotalSeconds > 7)
                    {
                        audioFileCount = audioFileCount + 1; // increment the audio file count

                        // delete the file if it exists
                        if (File.Exists($"output_{audioFileCount}.wav"))
                        {
                            File.Delete($"output_{audioFileCount}.wav");
                        }

                        using (BinaryWriter writer = new BinaryWriter(File.Open($"output_{audioFileCount}.wav", FileMode.Append)))
                        {
                            Console.WriteLine("Adding WAV header to output.wav");
                            byte[] wavHeader = new byte[44];
                            int sampleRate = 48000;
                            short bitsPerSample = 16;
                            short channels = 1;
                            int byteRate = sampleRate * channels * (bitsPerSample / 8);
                            short blockAlign = (short)(channels * (bitsPerSample / 8));

                            wavHeader[0] = 0x52; // R
                            wavHeader[1] = 0x49; // I
                            wavHeader[2] = 0x46; // F
                            wavHeader[3] = 0x46; // F
                            wavHeader[4] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[5] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[6] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[7] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[8] = 0x57; // W
                            wavHeader[9] = 0x41; // A
                            wavHeader[10] = 0x56; // V
                            wavHeader[11] = 0x45; // E
                            wavHeader[12] = 0x66; // f
                            wavHeader[13] = 0x6D; // m
                            wavHeader[14] = 0x74; // t
                            wavHeader[15] = 0x20; // Space
                            wavHeader[16] = 0x10; // Subchunk1Size (16 for PCM)
                            wavHeader[17] = 0x00; // Subchunk1Size
                            wavHeader[18] = 0x00; // Subchunk1Size
                            wavHeader[19] = 0x00; // Subchunk1Size
                            wavHeader[20] = 0x01; // AudioFormat (1 for PCM)
                            wavHeader[21] = 0x00; // AudioFormat
                            wavHeader[22] = (byte)channels; // NumChannels
                            wavHeader[23] = 0x00; // NumChannels
                            wavHeader[24] = (byte)(sampleRate & 0xFF); // SampleRate
                            wavHeader[25] = (byte)((sampleRate >> 8) & 0xFF); // SampleRate
                            wavHeader[26] = (byte)((sampleRate >> 16) & 0xFF); // SampleRate
                            wavHeader[27] = (byte)((sampleRate >> 24) & 0xFF); // SampleRate
                            wavHeader[28] = (byte)(byteRate & 0xFF); // ByteRate
                            wavHeader[29] = (byte)((byteRate >> 8) & 0xFF); // ByteRate
                            wavHeader[30] = (byte)((byteRate >> 16) & 0xFF); // ByteRate
                            wavHeader[31] = (byte)((byteRate >> 24) & 0xFF); // ByteRate
                            wavHeader[32] = (byte)blockAlign; // BlockAlign
                            wavHeader[33] = 0x00; // BlockAlign
                            wavHeader[34] = (byte)bitsPerSample; // BitsPerSample
                            wavHeader[35] = 0x00; // BitsPerSample
                            wavHeader[36] = 0x64; // d
                            wavHeader[37] = 0x61; // t
                            wavHeader[38] = 0x74; // t
                            wavHeader[39] = 0x61; // a
                            wavHeader[40] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[41] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[42] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[43] = 0x00; // Placeholder for data chunk size (will be updated later)

                            writer.Write(wavHeader);
                        }
                    }

                    if (e.Stream != null)
                    {
                        using (BinaryWriter writer = new BinaryWriter(File.Open($"output_{audioFileCount}.wav", FileMode.Append)))
                        {
                            writer.Write(e.Stream.ToArray());
                        }
                    }

                    // record the last audio time
                    lastAudioTime = DateTime.Now;
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AudioResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentAudioDoneResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentAudioDoneResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentStartedSpeakingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentStartedSpeakingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentThinkingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentThinkingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<ConversationTextResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to ConversationTextResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<UserStartedSpeakingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to UserStartedSpeakingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<WelcomeResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to WelcomeResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<CloseResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to CloseResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<SettingsAppliedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to SettingsAppliedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<InjectionRefusedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to InjectionRefusedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<PromptUpdatedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to PromptUpdatedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<SpeakUpdatedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received.");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to SpeakUpdatedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<UnhandledResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to UnhandledResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<ErrorResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received. Error: {e.Message}");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to ErrorResponse event");
                    return;
                }

                // Fetch and stream audio from URL
                string url = "https://dpgr.am/spacewalk.wav";
                using (var httpClient = new HttpClient())
                {
                    var response = await httpClient.GetAsync(url);
                    var stream = await response.Content.ReadAsStreamAsync();
                    var buffer = new byte[8192];
                    int bytesRead;

                    while ((bytesRead = await stream.ReadAsync(buffer, 0, buffer.Length)) > 0)
                    {
                        var chunk = new byte[bytesRead];
                        Array.Copy(buffer, chunk, bytesRead);
                        await agentClient.SendBinaryImmediately(chunk);
                    }
                }

                // Wait for the user to press a key
                Console.ReadKey();

                // Stop the connection
                await agentClient.Stop();

                // Terminate Libraries
                Deepgram.Library.Terminate();
            }
            catch (Exception ex)
            {
                Console.WriteLine($"Exception: {ex.Message}");
            }
        }
    }
}
  ```
  ```go Go
  // 4. Setup Event Handlers
func (dch MyHandler) Run() error {
	wgReceivers := sync.WaitGroup{}

	// Handle binary data
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		counter := 0
		lastBytesReceived := time.Now().Add(-7 * time.Second)

		for br := range dch.binaryChan {
			fmt.Printf("\n\n[Binary Data Received]\n")
			fmt.Printf("Size: %d bytes\n", len(*br))

			if lastBytesReceived.Add(5 * time.Second).Before(time.Now()) {
				counter = counter + 1
				file, err := os.OpenFile(fmt.Sprintf("output_%d.wav", counter), os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0o666)
				if err != nil {
					fmt.Printf("Failed to open file. Err: %v\n", err)
					continue
				}
				// Add WAV header
				header := []byte{
					0x52, 0x49, 0x46, 0x46, // "RIFF"
					0x00, 0x00, 0x00, 0x00, // Placeholder for file size
					0x57, 0x41, 0x56, 0x45, // "WAVE"
					0x66, 0x6d, 0x74, 0x20, // "fmt "
					0x10, 0x00, 0x00, 0x00, // Chunk size (16)
					0x01, 0x00, // Audio format (1 for PCM)
					0x01, 0x00, // Number of channels (1)
					0x80, 0x5d, 0x00, 0x00, // Sample rate (24000)
					0x00, 0xbb, 0x00, 0x00, // Byte rate (24000 * 2)
					0x02, 0x00, // Block align (2)
					0x10, 0x00, // Bits per sample (16)
					0x64, 0x61, 0x74, 0x61, // "data"
					0x00, 0x00, 0x00, 0x00, // Placeholder for data size
				}

				_, err = file.Write(header)
				if err != nil {
					fmt.Printf("Failed to write header to file. Err: %v\n", err)
					continue
				}
				file.Close()
			}

			file, err := os.OpenFile(fmt.Sprintf("output_%d.wav", counter), os.O_APPEND|os.O_WRONLY, 0o644)
			if err != nil {
				fmt.Printf("Failed to open file. Err: %v\n", err)
				continue
			}

			_, err = file.Write(*br)
			file.Close()

			if err != nil {
				fmt.Printf("Failed to write to file. Err: %v\n", err)
				continue
			}

			lastBytesReceived = time.Now()
		}
	}()

	// Handle conversation text
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		var currentSpeaker string
		var currentMessage strings.Builder
		lastUpdate := time.Now()

		for ctr := range dch.conversationTextResponse {
			// If speaker changed or it's been more than 2 seconds, print accumulated message
			if currentSpeaker != ctr.Role || time.Since(lastUpdate) > 2*time.Second {
				if currentMessage.Len() > 0 {
					fmt.Printf("\n\n[ConversationTextResponse]\n")
					fmt.Printf("%s: %s\n\n", currentSpeaker, currentMessage.String())

					// Write to chat log
					if err := dch.writeToChatLog(currentSpeaker, currentMessage.String()); err != nil {
						fmt.Printf("Failed to write to chat log: %v\n", err)
					}
				}
				currentSpeaker = ctr.Role
				currentMessage.Reset()
			}

			// Add new content to current message
			if currentMessage.Len() > 0 {
				currentMessage.WriteString(" ")
			}
			currentMessage.WriteString(ctr.Content)
			lastUpdate = time.Now()

			// Track conversation flow
			switch ctr.Role {
			case "user":
				fmt.Printf("Received user message: %s\n", ctr.Content)
				fmt.Printf("Waiting for agent to process...\n")
			case "assistant":
				fmt.Printf("Agent response: %s\n", ctr.Content)
				fmt.Printf("Waiting for next user input...\n")
			default:
				fmt.Printf("Received message from %s: %s\n", ctr.Role, ctr.Content)
			}
		}

		// Print any remaining message
		if currentMessage.Len() > 0 {
			fmt.Printf("\n\n[ConversationTextResponse]\n")
			fmt.Printf("%s: %s\n\n", currentSpeaker, currentMessage.String())

			// Write to chat log
			if err := dch.writeToChatLog(currentSpeaker, currentMessage.String()); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle user started speaking
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for range dch.userStartedSpeakingResponse {
			fmt.Printf("\n\n[UserStartedSpeakingResponse]\n")
			fmt.Printf("User has started speaking, waiting for completion...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", "User has started speaking"); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle agent thinking
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for atr := range dch.agentThinkingResponse {
			fmt.Printf("\n\n[AgentThinkingResponse]\n")
			fmt.Printf("Agent is processing input: %s\n", atr.Content)
			fmt.Printf("Waiting for agent's response...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", fmt.Sprintf("Agent is processing: %s", atr.Content)); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle agent started speaking
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for asr := range dch.agentStartedSpeakingResponse {
			fmt.Printf("\n\n[AgentStartedSpeakingResponse]\n")
			fmt.Printf("Agent is starting to respond (latency: %.2fms)\n", asr.TotalLatency)
			fmt.Printf("Processing agent's response...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", "Agent is starting to respond"); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle agent audio done
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for range dch.agentAudioDoneResponse {
			fmt.Printf("\n\n[AgentAudioDoneResponse]\n")
			fmt.Printf("Agent finished speaking, waiting for next user input...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", "Agent finished speaking"); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle keep alive responses
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for range dch.keepAliveResponse {
			fmt.Printf("\n\n[KeepAliveResponse]\n")
			fmt.Printf("Connection is alive, waiting for next event...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", "Keep alive received"); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle other events
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for range dch.openChan {
			fmt.Printf("\n\n[OpenResponse]\n\n")
		}
	}()

	// welcome channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for range dch.welcomeResponse {
			fmt.Printf("\n\n[WelcomeResponse]\n\n")
		}
	}()

	// settings applied channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for range dch.settingsAppliedResponse {
			fmt.Printf("\n\n[SettingsAppliedResponse]\n\n")
		}
	}()

	// close channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for closeResp := range dch.closeChan {
			fmt.Printf("\n\n[CloseResponse]\n")
			fmt.Printf(" Close response received\n")
			fmt.Printf(" Close response type: %+v\n", closeResp)
			fmt.Printf("\n")
		}
	}()

	// error channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for er := range dch.errorChan {
			fmt.Printf("\n[ErrorResponse]\n")
			fmt.Printf("\nError.Type: %s\n", er.ErrCode)
			fmt.Printf("Error.Message: %s\n", er.ErrMsg)
			fmt.Printf("Error.Description: %s\n\n", er.Description)
			fmt.Printf("Error.Variant: %s\n\n", er.Variant)
		}
	}()

	// unhandled event channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for byData := range dch.unhandledChan {
			fmt.Printf("\n[UnhandledEvent]\n")
			fmt.Printf("Raw message: %s\n", string(*byData))
		}
	}()

	// Handle function call request
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for range dch.functionCallRequestResponse {
			fmt.Printf("\n\n[FunctionCallRequestResponse]\n\n")
		}
	}()

	// Wait for all receivers to finish
	wgReceivers.Wait()
	return nil
}

// Helper function to write to chat log
func (dch *MyHandler) writeToChatLog(role, content string) error {
	if dch.chatLogFile == nil {
		return fmt.Errorf("chat log file not initialized")
	}

	timestamp := time.Now().Format("2006-01-02 15:04:05")
	logEntry := fmt.Sprintf("[%s] %s: %s\n", timestamp, role, content)

	_, err := dch.chatLogFile.WriteString(logEntry)
	if err != nil {
		return fmt.Errorf("failed to write to chat log: %v", err)
	}

	return nil
}

// Main function
func main() {
	fmt.Printf(" Program starting\n")
	// Print instructions
	fmt.Print("\n\nPress ENTER to exit!\n\n")

	// Initialize context
	ctx := context.Background()
	fmt.Printf(" Context initialized\n")

	// Configure agent
	cOptions := configureAgent()
	fmt.Printf(" Agent configured\n")

	// Set transcription options
	tOptions := client.NewSettingsConfigurationOptions()
	tOptions.Audio.Input.Encoding = "linear16"
	tOptions.Audio.Input.SampleRate = 48000
	tOptions.Agent.Think.Provider.Type = "open_ai"
	tOptions.Agent.Think.Provider.Model = "gpt-4o-mini"
	tOptions.Agent.Think.Prompt = "You are a helpful AI assistant."
	tOptions.Agent.Listen.Provider.Type = "deepgram"
	tOptions.Agent.Listen.Provider.Model = "nova-3"
	tOptions.Agent.Speak.Provider.Type = "deepgram"
	tOptions.Agent.Speak.Provider.Model = "aura-2-thalia-en"
	tOptions.Agent.Language = "en"
	tOptions.Agent.Greeting = "Hello! How can I help you today?"
	fmt.Printf(" Transcription options set\n")

	// Create handler
	fmt.Printf("Creating new Deepgram WebSocket client...\n")
	handler := NewMyHandler()
	if handler == nil {
		fmt.Printf("Failed to create handler\n")
		return
	}
	fmt.Printf(" Handler created\n")
	defer handler.chatLogFile.Close()

	// Create client
	callback := msginterfaces.AgentMessageChan(*handler)
	fmt.Printf(" Callback created\n")
	dgClient, err := client.NewWSUsingChan(ctx, "", cOptions, tOptions, callback)
	if err != nil {
		fmt.Printf("ERROR creating LiveTranscription connection:\n- Error: %v\n- Type: %T\n", err, err)
		return
	}
	fmt.Printf(" Deepgram client created\n")

	// Connect to Deepgram
	fmt.Printf("Attempting to connect to Deepgram WebSocket...\n")
	bConnected := dgClient.Connect()
	if !bConnected {
		fmt.Printf("WebSocket connection failed - check your API key and network connection\n")
		os.Exit(1)
	}
	fmt.Printf(" Successfully connected to Deepgram WebSocket\n")

	// Stream audio from URL
	audioURL := "https://dpgr.am/spacewalk.wav"
	httpClient := new(http.Client)
	resp, err := httpClient.Get(audioURL)
	if err != nil {
		fmt.Printf("Failed to fetch audio from URL. Err: %v\n", err)
		return
	}
	fmt.Printf(" Audio URL fetched, content length: %d bytes\n", resp.ContentLength)
	fmt.Printf("Stream is up and running %s\n", reflect.TypeOf(resp))
	buf := bufio.NewReaderSize(resp.Body, 960*200) // Increase buffer to handle 200 chunks at once
	go func() {
		fmt.Printf(" Starting audio stream goroutine\n")
		fmt.Printf("Starting to stream audio from URL...\n")
		defer resp.Body.Close()
		err = dgClient.Stream(buf)
		if err != nil && err != io.EOF {
			fmt.Printf("Failed to stream audio. Err: %v\n", err)
			return
		}
		fmt.Printf(" Audio stream completed\n")
		fmt.Printf("Finished streaming audio from URL\n")
	}()

	// Wait for user input to exit
	fmt.Printf(" Waiting for user input\n")
	input := bufio.NewScanner(os.Stdin)
	input.Scan()
	fmt.Printf(" User input received\n")

	// Cleanup
	fmt.Printf(" Starting cleanup sequence...\n")
	fmt.Printf(" Calling dgClient.Stop()\n")
	dgClient.Stop()
	fmt.Printf(" dgClient.Stop() completed\n")
	fmt.Printf("\n\nProgram exiting...\n")
}
  ```
</CodeGroup>

### 7. Run the Voice Agent
Now that you have your complete code, you can run the Voice Agent! If it works you should see the conversation text and audio in the files: `output-0.wav` and `chatlog.txt`. These files will be saved in the same directory as your main application file.

<CodeGroup>
  ```python Python
  python main.py
  ```
  ```javascript JavaScript
  node index.js
  ```
  ```csharp C#
  dotnet run Program.cs
  ```
  ```go Go
  go run main.go
  ```
</CodeGroup>

### 8. Putting it all together

Below is the final code for the Voice Agent you just built. If you saw any errors after running your Agent, you can compare the code below to the code you wrote in the steps above to find and fix the errors.

<CodeGroup>
  ```python Python
  # For help migrating to the new Python SDK, check out our migration guide:
  # https://github.com/deepgram/deepgram-python-sdk/blob/main/docs/Migrating-v3-to-v5.md

  # Copyright 2025 Deepgram SDK contributors. All Rights Reserved.
# Use of this source code is governed by a MIT license that can be found in the LICENSE file.
# SPDX-License-Identifier: MIT

# Import dependencies and set up the main function
import requests
import time
import os
import json
import threading

from deepgram import DeepgramClient
from deepgram.core.events import EventType
from deepgram.extensions.types.sockets import (
    AgentV1Agent,
    AgentV1AudioConfig,
    AgentV1AudioInput,
    AgentV1AudioOutput,
    AgentV1DeepgramSpeakProvider,
    AgentV1Listen,
    AgentV1ListenProvider,
    AgentV1OpenAiThinkProvider,
    AgentV1SettingsMessage,
    AgentV1SocketClientResponse,
    AgentV1SpeakProviderConfig,
    AgentV1Think,
)

def main():
    try:
        # Initialize the Voice Agent
        api_key = os.getenv("DEEPGRAM_API_KEY")
        if not api_key:
            raise ValueError("DEEPGRAM_API_KEY environment variable is not set")
        print("API Key found")

        # Initialize Deepgram client
        client = DeepgramClient(api_key=api_key)

        # Use connection as a context manager
        with client.agent.v1.connect() as connection:
            print("Created WebSocket connection...")

            # Configure the Agent
            settings = AgentV1SettingsMessage(
                audio=AgentV1AudioConfig(
                    input=AgentV1AudioInput(
                        encoding="linear16",
                        sample_rate=24000,
                    ),
                    output=AgentV1AudioOutput(
                        encoding="linear16",
                        sample_rate=24000,
                        container="wav",
                    ),
                ),
                agent=AgentV1Agent(
                    language="en",
                    listen=AgentV1Listen(
                        provider=AgentV1ListenProvider(
                            type="deepgram",
                            model="nova-3",
                        )
                    ),
                    think=AgentV1Think(
                        provider=AgentV1OpenAiThinkProvider(
                            type="open_ai",
                            model="gpt-4o-mini",
                        ),
                        prompt="You are a friendly AI assistant.",
                    ),
                    speak=AgentV1SpeakProviderConfig(
                        provider=AgentV1DeepgramSpeakProvider(
                            type="deepgram",
                            model="aura-2-thalia-en",
                        )
                    ),
                    greeting="Hello! How can I help you today?",
                ),
            )

            # Setup Event Handlers
            audio_buffer = bytearray()
            file_counter = 0
            processing_complete = False

            def on_open(event):
                print("Connection opened")

            def on_message(message: AgentV1SocketClientResponse):
                nonlocal audio_buffer, file_counter, processing_complete

                # Handle binary audio data
                if isinstance(message, bytes):
                    audio_buffer.extend(message)
                    print(f"Received audio data: {len(message)} bytes")
                    return

                # Handle different message types
                msg_type = getattr(message, "type", "Unknown")
                print(f"Received {msg_type} event")

                # Handle specific event types
                if msg_type == "Welcome":
                    print(f"Welcome: {message}")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"Welcome: {message}\n")

                elif msg_type == "SettingsApplied":
                    print(f"Settings applied: {message}")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"Settings applied: {message}\n")

                elif msg_type == "ConversationText":
                    print(f"Conversation: {message}")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"{json.dumps(message.__dict__)}\n")

                elif msg_type == "UserStartedSpeaking":
                    print(f"User started speaking")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"User started speaking\n")

                elif msg_type == "AgentThinking":
                    print(f"Agent thinking")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"Agent thinking\n")

                elif msg_type == "AgentStartedSpeaking":
                    audio_buffer = bytearray()  # Reset buffer for new response
                    print(f"Agent started speaking")
                    with open("chatlog.txt", 'a') as chatlog:
                        chatlog.write(f"Agent started speaking\n")

                elif msg_type == "AgentAudioDone":
                    print(f"Agent audio done")
                    if len(audio_buffer) > 0:
                        with open(f"output-{file_counter}.wav", 'wb') as f:
                            f.write(create_wav_header())
                            f.write(audio_buffer)
                        print(f"Created output-{file_counter}.wav")
                    audio_buffer = bytearray()
                    file_counter += 1
                    processing_complete = True

            def on_error(error):
                print(f"Error: {error}")
                with open("chatlog.txt", 'a') as chatlog:
                    chatlog.write(f"Error: {error}\n")

            def on_close(event):
                print(f"Connection closed")
                with open("chatlog.txt", 'a') as chatlog:
                    chatlog.write(f"Connection closed\n")

            # Register event handlers
            connection.on(EventType.OPEN, on_open)
            connection.on(EventType.MESSAGE, on_message)
            connection.on(EventType.ERROR, on_error)
            connection.on(EventType.CLOSE, on_close)
            print("Event handlers registered")

            # Send settings to configure the agent
            print("Sending settings configuration...")
            connection.send_settings(settings)
            print("Settings sent successfully")

            # Start listening for events in a background thread
            print("Starting event listener...")
            listener_thread = threading.Thread(target=connection.start_listening, daemon=True)
            listener_thread.start()

            # Wait a moment for connection to establish
            time.sleep(1)

            # Stream audio
            print("Downloading and sending audio...")
            response = requests.get("https://dpgr.am/spacewalk.wav", stream=True)
            # Skip WAV header
            header = response.raw.read(44)

            # Verify WAV header
            if header[0:4] != b'RIFF' or header[8:12] != b'WAVE':
                print("Invalid WAV header")
                return

            chunk_size = 8192
            total_bytes_sent = 0
            chunk_count = 0
            for chunk in response.iter_content(chunk_size=chunk_size):
                if chunk:
                    print(f"Sending chunk {chunk_count}: {len(chunk)} bytes")
                    connection.send_media(chunk)
                    total_bytes_sent += len(chunk)
                    chunk_count += 1
                    time.sleep(0.1)  # Small delay between chunks

            print(f"Total audio data sent: {total_bytes_sent} bytes in {chunk_count} chunks")
            print("Waiting for agent response...")

            # Wait for processing
            print("Waiting for processing to complete...")
            start_time = time.time()
            timeout = 30  # 30 second timeout

            while not processing_complete and (time.time() - start_time) < timeout:
                time.sleep(1)
                print(f"Still waiting for agent response... ({int(time.time() - start_time)}s elapsed)")

            if not processing_complete:
                print("Processing timed out after 30 seconds")
            else:
                print("Processing complete. Check output-*.wav and chatlog.txt for results.")

            print("Finished")

    except Exception as e:
        print(f"Error: {str(e)}")

# WAV Header Functions
def create_wav_header(sample_rate=24000, bits_per_sample=16, channels=1):
    """Create a WAV header with the specified parameters"""
    byte_rate = sample_rate * channels * (bits_per_sample // 8)
    block_align = channels * (bits_per_sample // 8)

    header = bytearray(44)
    # RIFF header
    header[0:4] = b'RIFF'
    header[4:8] = b'\x00\x00\x00\x00'  # File size (to be updated later)
    header[8:12] = b'WAVE'
    # fmt chunk
    header[12:16] = b'fmt '
    header[16:20] = b'\x10\x00\x00\x00'  # Subchunk1Size (16 for PCM)
    header[20:22] = b'\x01\x00'  # AudioFormat (1 for PCM)
    header[22:24] = channels.to_bytes(2, 'little')  # NumChannels
    header[24:28] = sample_rate.to_bytes(4, 'little')  # SampleRate
    header[28:32] = byte_rate.to_bytes(4, 'little')  # ByteRate
    header[32:34] = block_align.to_bytes(2, 'little')  # BlockAlign
    header[34:36] = bits_per_sample.to_bytes(2, 'little')  # BitsPerSample
    # data chunk
    header[36:40] = b'data'
    header[40:44] = b'\x00\x00\x00\x00'  # Subchunk2Size (to be updated later)

    return header

if __name__ == "__main__":
    main()

  ```
  ```javascript JavaScript
const { writeFile, appendFile } = require("fs/promises");
const { createClient, AgentEvents } = require("@deepgram/sdk");
const fetch = require("cross-fetch");
const { join } = require("path");

const deepgram = createClient(process.env.DEEPGRAM_API_KEY);

const agent = async () => {
  let audioBuffer = Buffer.alloc(0);
  let i = 0;
  const url = "https://dpgr.am/spacewalk.wav";
  const connection = deepgram.agent();
  connection.on(AgentEvents.Welcome, () => {
    console.log("Welcome to the Deepgram Voice Agent!");

    connection.configure({
      audio: {
        input: {
          encoding: "linear16",
          sample_rate: 24000,
        },
        output: {
          encoding: "linear16",
          sample_rate: 16000,
          container: "wav",
        },
      },
      agent: {
        language: "en",
        listen: {
          provider: {
            type: "deepgram",
            model: "nova-3",
          },
        },
        think: {
          provider: {
            type: "open_ai",
            model: "gpt-4o-mini",
          },
          prompt: "You are a friendly AI assistant.",
        },
        speak: {
          provider: {
            type: "deepgram",
            model: "aura-2-thalia-en",
          },
        },
        greeting: "Hello! How can I help you today?",
      },
    });

    console.log("Deepgram agent configured!");

    setInterval(() => {
      console.log("Keep alive!");
      connection.keepAlive();
    }, 5000);

    fetch(url)
      .then((r) => r.body)
      .then((res) => {
        res.on("readable", () => {
          console.log("Sending audio chunk");
          connection.send(res.read());
        });
      });
  });

  connection.on(AgentEvents.Open, () => {
    console.log("Connection opened");
  });

  connection.on(AgentEvents.Close, () => {
    console.log("Connection closed");
    process.exit(0);
  });

  connection.on(AgentEvents.ConversationText, async (data) => {
    await appendFile(join(__dirname, `chatlog.txt`), JSON.stringify(data) + "\n");
  });

  connection.on(AgentEvents.UserStartedSpeaking, () => {
    if (audioBuffer.length) {
      console.log("Interrupting agent.");
      audioBuffer = Buffer.alloc(0);
    }
  });

  connection.on(AgentEvents.Metadata, (data) => {
    console.dir(data, { depth: null });
  });

  connection.on(AgentEvents.Audio, (data) => {
    console.log("Audio chunk received");
    // Concatenate the audio chunks into a single buffer
    const buffer = Buffer.from(data);
    audioBuffer = Buffer.concat([audioBuffer, buffer]);
  });

  connection.on(AgentEvents.Error, (err) => {
    console.error("Error!");
    console.error(JSON.stringify(err, null, 2));
    console.error(err.message);
  });

  connection.on(AgentEvents.AgentAudioDone, async () => {
    console.log("Agent audio done");
    await writeFile(join(__dirname, `output-${i}.wav`), audioBuffer);
    audioBuffer = Buffer.alloc(0);
    i++;
  });

  connection.on(AgentEvents.Unhandled, (data) => {
    console.dir(data, { depth: null });
  });
};

void agent();

  ```
  ```csharp C#
// Copyright 2024 Deepgram .NET SDK contributors. All Rights Reserved.
// Use of this source code is governed by a MIT license that can be found in the LICENSE file.
// SPDX-License-Identifier: MIT

using Deepgram.Logger;
using Deepgram.Models.Authenticate.v1;
using Deepgram.Models.Agent.v2.WebSocket;
using System.Collections.Generic;
using System.Net.Http;

namespace SampleApp
{
    class Program
    {
        static async Task Main(string[] args)
        {
            try
            {
                // Initialize Library with default logging
                // Normal logging is "Info" level
                Deepgram.Library.Initialize(LogLevel.Debug);
                // OR very chatty logging
                //Deepgram.Library.Initialize(LogLevel.Verbose); // LogLevel.Default, LogLevel.Debug, LogLevel.Verbose

                Console.WriteLine("\n\nPress any key to stop and exit...\n\n\n");

                // Set "DEEPGRAM_API_KEY" environment variable to your Deepgram API Key
                DeepgramWsClientOptions options = new DeepgramWsClientOptions(null, null, true);
                var agentClient = ClientFactory.CreateAgentWebSocketClient(apiKey: "", options: options);

                // current time
                var lastAudioTime = DateTime.Now;
                var audioFileCount = 0;

                // Start the connection
                var settingsConfiguration = new SettingsSchema();
                settingsConfiguration.Agent.Think.Provider.Type = "open_ai";
                settingsConfiguration.Agent.Think.Provider.Model = "gpt-4o-mini";
                settingsConfiguration.Audio.Output.SampleRate = 24000;
                settingsConfiguration.Audio.Output.Container = "wav";
                settingsConfiguration.Audio.Input.SampleRate = 24000;
                settingsConfiguration.Agent.Greeting = "Hello, how can I help you today?";
                settingsConfiguration.Agent.Listen.Provider.Model = "nova-3";
                settingsConfiguration.Agent.Listen.Provider.Keyterms = new List<string> { "Deepgram" };
                settingsConfiguration.Agent.Speak.Provider.Type = "deepgram";
                settingsConfiguration.Agent.Speak.Provider.Model = "aura-2-thalia-en";

                // To avoid issues with empty objects, Voice and Endpoint are instantiated as null. Construct them as needed.
                // settingsConfiguration.Agent.Speak.Provider.Voice = new CartesiaVoice();
                // settingsConfiguration.Agent.Speak.Provider.Voice.Id = "en-US-Wavenet-D";
                // settingsConfiguration.Agent.Speak.Endpoint = new Endpoint();
                // settingsConfiguration.Agent.Think.Endpoint = new Endpoint();

                bool bConnected = await agentClient.Connect(settingsConfiguration);
                if (!bConnected)
                {
                    Console.WriteLine("Failed to connect to Deepgram WebSocket server.");
                    return;
                }

                // Subscribe to the EventResponseReceived event
                var subscribeResult = await agentClient.Subscribe(new EventHandler<OpenResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e.Type} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to OpenResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AudioResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e.Type} received");

                    // if the last audio response is more than 5 seconds ago, add a wav header
                    if (DateTime.Now.Subtract(lastAudioTime).TotalSeconds > 7)
                    {
                        audioFileCount = audioFileCount + 1; // increment the audio file count

                        // delete the file if it exists
                        if (File.Exists($"output_{audioFileCount}.wav"))
                        {
                            File.Delete($"output_{audioFileCount}.wav");
                        }

                        using (BinaryWriter writer = new BinaryWriter(File.Open($"output_{audioFileCount}.wav", FileMode.Append)))
                        {
                            Console.WriteLine("Adding WAV header to output.wav");
                            byte[] wavHeader = new byte[44];
                            int sampleRate = 24000;
                            short bitsPerSample = 16;
                            short channels = 1;
                            int byteRate = sampleRate * channels * (bitsPerSample / 8);
                            short blockAlign = (short)(channels * (bitsPerSample / 8));

                            wavHeader[0] = 0x52; // R
                            wavHeader[1] = 0x49; // I
                            wavHeader[2] = 0x46; // F
                            wavHeader[3] = 0x46; // F
                            wavHeader[4] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[5] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[6] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[7] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[8] = 0x57; // W
                            wavHeader[9] = 0x41; // A
                            wavHeader[10] = 0x56; // V
                            wavHeader[11] = 0x45; // E
                            wavHeader[12] = 0x66; // f
                            wavHeader[13] = 0x6D; // m
                            wavHeader[14] = 0x74; // t
                            wavHeader[15] = 0x20; // Space
                            wavHeader[16] = 0x10; // Subchunk1Size (16 for PCM)
                            wavHeader[17] = 0x00; // Subchunk1Size
                            wavHeader[18] = 0x00; // Subchunk1Size
                            wavHeader[19] = 0x00; // Subchunk1Size
                            wavHeader[20] = 0x01; // AudioFormat (1 for PCM)
                            wavHeader[21] = 0x00; // AudioFormat
                            wavHeader[22] = (byte)channels; // NumChannels
                            wavHeader[23] = 0x00; // NumChannels
                            wavHeader[24] = (byte)(sampleRate & 0xFF); // SampleRate
                            wavHeader[25] = (byte)((sampleRate >> 8) & 0xFF); // SampleRate
                            wavHeader[26] = (byte)((sampleRate >> 16) & 0xFF); // SampleRate
                            wavHeader[27] = (byte)((sampleRate >> 24) & 0xFF); // SampleRate
                            wavHeader[28] = (byte)(byteRate & 0xFF); // ByteRate
                            wavHeader[29] = (byte)((byteRate >> 8) & 0xFF); // ByteRate
                            wavHeader[30] = (byte)((byteRate >> 16) & 0xFF); // ByteRate
                            wavHeader[31] = (byte)((byteRate >> 24) & 0xFF); // ByteRate
                            wavHeader[32] = (byte)blockAlign; // BlockAlign
                            wavHeader[33] = 0x00; // BlockAlign
                            wavHeader[34] = (byte)bitsPerSample; // BitsPerSample
                            wavHeader[35] = 0x00; // BitsPerSample
                            wavHeader[36] = 0x64; // d
                            wavHeader[37] = 0x61; // t
                            wavHeader[38] = 0x74; // t
                            wavHeader[39] = 0x61; // a
                            wavHeader[40] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[41] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[42] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[43] = 0x00; // Placeholder for data chunk size (will be updated later)

                            writer.Write(wavHeader);
                        }
                    }

                    if (e.Stream != null)
                    {
                        using (BinaryWriter writer = new BinaryWriter(File.Open($"output_{audioFileCount}.wav", FileMode.Append)))
                        {
                            writer.Write(e.Stream.ToArray());
                        }
                    }

                    // record the last audio time
                    lastAudioTime = DateTime.Now;
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AudioResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentAudioDoneResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentAudioDoneResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentStartedSpeakingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentStartedSpeakingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentThinkingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentThinkingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<ConversationTextResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to ConversationTextResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<UserStartedSpeakingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to UserStartedSpeakingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<WelcomeResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to WelcomeResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<CloseResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to CloseResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<SettingsAppliedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to SettingsAppliedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<InjectionRefusedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to InjectionRefusedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<PromptUpdatedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to PromptUpdatedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<SpeakUpdatedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received.");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to SpeakUpdatedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<UnhandledResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to UnhandledResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<ErrorResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received. Error: {e.Message}");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to ErrorResponse event");
                    return;
                }

                // Fetch and stream audio from URL
                string url = "https://dpgr.am/spacewalk.wav";
                using (var httpClient = new HttpClient())
                {
                    var response = await httpClient.GetAsync(url);
                    var stream = await response.Content.ReadAsStreamAsync();
                    var buffer = new byte[8192];
                    int bytesRead;

                    while ((bytesRead = await stream.ReadAsync(buffer, 0, buffer.Length)) > 0)
                    {
                        var chunk = new byte[bytesRead];
                        Array.Copy(buffer, chunk, bytesRead);
                        await agentClient.SendBinaryImmediately(chunk);
                    }
                }

                // Wait for the user to press a key
                Console.ReadKey();

                // Stop the connection
                await agentClient.Stop();

                // Terminate Libraries
                Deepgram.Library.Terminate();
            }
            catch (Exception ex)
            {
                Console.WriteLine($"Exception: {ex.Message}");
            }
        }
    }
}
  ```
  ```go Go
// Copyright 2024 Deepgram SDK contributors. All Rights Reserved.
// Use of this source code is governed by a MIT license that can be found in the LICENSE file.
// SPDX-License-Identifier: MIT

package main

// Import dependencies
import (
	"bufio"
	"context"
	"fmt"
	"io"
	"net/http"
	"os"
	"reflect"
	"runtime/debug"
	"strings"
	"sync"
	"time"

	msginterfaces "github.com/deepgram/deepgram-go-sdk/pkg/api/agent/v1/websocket/interfaces"
	client "github.com/deepgram/deepgram-go-sdk/pkg/client/agent"
	"github.com/deepgram/deepgram-go-sdk/pkg/client/interfaces"
)

// Initialize the Voice Agent
type MyHandler struct {
	binaryChan                   chan *[]byte
	openChan                     chan *msginterfaces.OpenResponse
	welcomeResponse              chan *msginterfaces.WelcomeResponse
	conversationTextResponse     chan *msginterfaces.ConversationTextResponse
	userStartedSpeakingResponse  chan *msginterfaces.UserStartedSpeakingResponse
	agentThinkingResponse        chan *msginterfaces.AgentThinkingResponse
	agentStartedSpeakingResponse chan *msginterfaces.AgentStartedSpeakingResponse
	agentAudioDoneResponse       chan *msginterfaces.AgentAudioDoneResponse
	closeChan                    chan *msginterfaces.CloseResponse
	errorChan                    chan *msginterfaces.ErrorResponse
	unhandledChan                chan *[]byte
	injectionRefusedResponse     chan *msginterfaces.InjectionRefusedResponse
	keepAliveResponse            chan *msginterfaces.KeepAlive
	settingsAppliedResponse      chan *msginterfaces.SettingsAppliedResponse
	functionCallRequestResponse  chan *msginterfaces.FunctionCallRequestResponse
	chatLogFile                  *os.File
}

// Channel getter methods to implement AgentMessageChan interface
func (dch MyHandler) GetBinary() []*chan *[]byte {
	return []*chan *[]byte{&dch.binaryChan}
}

func (dch MyHandler) GetOpen() []*chan *msginterfaces.OpenResponse {
	return []*chan *msginterfaces.OpenResponse{&dch.openChan}
}

func (dch MyHandler) GetWelcome() []*chan *msginterfaces.WelcomeResponse {
	return []*chan *msginterfaces.WelcomeResponse{&dch.welcomeResponse}
}

func (dch MyHandler) GetConversationText() []*chan *msginterfaces.ConversationTextResponse {
	return []*chan *msginterfaces.ConversationTextResponse{&dch.conversationTextResponse}
}

func (dch MyHandler) GetUserStartedSpeaking() []*chan *msginterfaces.UserStartedSpeakingResponse {
	return []*chan *msginterfaces.UserStartedSpeakingResponse{&dch.userStartedSpeakingResponse}
}

func (dch MyHandler) GetAgentThinking() []*chan *msginterfaces.AgentThinkingResponse {
	return []*chan *msginterfaces.AgentThinkingResponse{&dch.agentThinkingResponse}
}

func (dch MyHandler) GetAgentStartedSpeaking() []*chan *msginterfaces.AgentStartedSpeakingResponse {
	return []*chan *msginterfaces.AgentStartedSpeakingResponse{&dch.agentStartedSpeakingResponse}
}

func (dch MyHandler) GetAgentAudioDone() []*chan *msginterfaces.AgentAudioDoneResponse {
	return []*chan *msginterfaces.AgentAudioDoneResponse{&dch.agentAudioDoneResponse}
}

func (dch MyHandler) GetClose() []*chan *msginterfaces.CloseResponse {
	return []*chan *msginterfaces.CloseResponse{&dch.closeChan}
}

func (dch MyHandler) GetError() []*chan *msginterfaces.ErrorResponse {
	return []*chan *msginterfaces.ErrorResponse{&dch.errorChan}
}

func (dch MyHandler) GetUnhandled() []*chan *[]byte {
	return []*chan *[]byte{&dch.unhandledChan}
}

func (dch MyHandler) GetInjectionRefused() []*chan *msginterfaces.InjectionRefusedResponse {
	return []*chan *msginterfaces.InjectionRefusedResponse{&dch.injectionRefusedResponse}
}

func (dch MyHandler) GetKeepAlive() []*chan *msginterfaces.KeepAlive {
	return []*chan *msginterfaces.KeepAlive{&dch.keepAliveResponse}
}

func (dch MyHandler) GetFunctionCallRequest() []*chan *msginterfaces.FunctionCallRequestResponse {
	return []*chan *msginterfaces.FunctionCallRequestResponse{&dch.functionCallRequestResponse}
}

func (dch MyHandler) GetSettingsApplied() []*chan *msginterfaces.SettingsAppliedResponse {
	return []*chan *msginterfaces.SettingsAppliedResponse{&dch.settingsAppliedResponse}
}

// Initialize the Voice Agent
func NewMyHandler() *MyHandler {
	// Create chat log file
	chatLogFile, err := os.OpenFile("chatlog.txt", os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil {
		fmt.Printf("Failed to create chat log file: %v\n", err)
		return nil
	}

	handler := &MyHandler{
		binaryChan:                   make(chan *[]byte),
		openChan:                     make(chan *msginterfaces.OpenResponse),
		welcomeResponse:              make(chan *msginterfaces.WelcomeResponse),
		conversationTextResponse:     make(chan *msginterfaces.ConversationTextResponse),
		userStartedSpeakingResponse:  make(chan *msginterfaces.UserStartedSpeakingResponse),
		agentThinkingResponse:        make(chan *msginterfaces.AgentThinkingResponse),
		agentStartedSpeakingResponse: make(chan *msginterfaces.AgentStartedSpeakingResponse),
		agentAudioDoneResponse:       make(chan *msginterfaces.AgentAudioDoneResponse),
		closeChan:                    make(chan *msginterfaces.CloseResponse),
		errorChan:                    make(chan *msginterfaces.ErrorResponse),
		unhandledChan:                make(chan *[]byte),
		injectionRefusedResponse:     make(chan *msginterfaces.InjectionRefusedResponse),
		keepAliveResponse:            make(chan *msginterfaces.KeepAlive),
		settingsAppliedResponse:      make(chan *msginterfaces.SettingsAppliedResponse),
		functionCallRequestResponse:  make(chan *msginterfaces.FunctionCallRequestResponse),
		chatLogFile:                  chatLogFile,
	}

	go func() {
		handler.Run()
	}()

	return handler
}

// Configure the Agent
func configureAgent() *interfaces.ClientOptions {
	// Initialize library
	client.Init(client.InitLib{
		LogLevel: client.LogLevelVerbose,
	})

	// Set client options
	return &interfaces.ClientOptions{
		EnableKeepAlive: true,
	}
}

// 4. Setup Event Handlers
func (dch MyHandler) Run() error {
	wgReceivers := sync.WaitGroup{}

	// Handle binary data
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		counter := 0
		lastBytesReceived := time.Now().Add(-7 * time.Second)

		for br := range dch.binaryChan {
			fmt.Printf("\n\n[Binary Data Received]\n")
			fmt.Printf("Size: %d bytes\n", len(*br))

			if lastBytesReceived.Add(5 * time.Second).Before(time.Now()) {
				counter = counter + 1
				file, err := os.OpenFile(fmt.Sprintf("output_%d.wav", counter), os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0o666)
				if err != nil {
					fmt.Printf("Failed to open file. Err: %v\n", err)
					continue
				}
				// Add WAV header
				header := []byte{
					0x52, 0x49, 0x46, 0x46, // "RIFF"
					0x00, 0x00, 0x00, 0x00, // Placeholder for file size
					0x57, 0x41, 0x56, 0x45, // "WAVE"
					0x66, 0x6d, 0x74, 0x20, // "fmt "
					0x10, 0x00, 0x00, 0x00, // Chunk size (16)
					0x01, 0x00, // Audio format (1 for PCM)
					0x01, 0x00, // Number of channels (1)
					0x80, 0x5d, 0x00, 0x00, // Sample rate (24000)
					0x00, 0xbb, 0x00, 0x00, // Byte rate (24000 * 2)
					0x02, 0x00, // Block align (2)
					0x10, 0x00, // Bits per sample (16)
					0x64, 0x61, 0x74, 0x61, // "data"
					0x00, 0x00, 0x00, 0x00, // Placeholder for data size
				}

				_, err = file.Write(header)
				if err != nil {
					fmt.Printf("Failed to write header to file. Err: %v\n", err)
					continue
				}
				file.Close()
			}

			file, err := os.OpenFile(fmt.Sprintf("output_%d.wav", counter), os.O_APPEND|os.O_WRONLY, 0o644)
			if err != nil {
				fmt.Printf("Failed to open file. Err: %v\n", err)
				continue
			}

			_, err = file.Write(*br)
			file.Close()

			if err != nil {
				fmt.Printf("Failed to write to file. Err: %v\n", err)
				continue
			}

			lastBytesReceived = time.Now()
		}
	}()

	// Handle conversation text
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		var currentSpeaker string
		var currentMessage strings.Builder
		lastUpdate := time.Now()

		for ctr := range dch.conversationTextResponse {
			// If speaker changed or it's been more than 2 seconds, print accumulated message
			if currentSpeaker != ctr.Role || time.Since(lastUpdate) > 2*time.Second {
				if currentMessage.Len() > 0 {
					fmt.Printf("\n\n[ConversationTextResponse]\n")
					fmt.Printf("%s: %s\n\n", currentSpeaker, currentMessage.String())

					// Write to chat log
					if err := dch.writeToChatLog(currentSpeaker, currentMessage.String()); err != nil {
						fmt.Printf("Failed to write to chat log: %v\n", err)
					}
				}
				currentSpeaker = ctr.Role
				currentMessage.Reset()
			}

			// Add new content to current message
			if currentMessage.Len() > 0 {
				currentMessage.WriteString(" ")
			}
			currentMessage.WriteString(ctr.Content)
			lastUpdate = time.Now()

			// Track conversation flow
			switch ctr.Role {
			case "user":
				fmt.Printf("Received user message: %s\n", ctr.Content)
				fmt.Printf("Waiting for agent to process...\n")
			case "assistant":
				fmt.Printf("Agent response: %s\n", ctr.Content)
				fmt.Printf("Waiting for next user input...\n")
			default:
				fmt.Printf("Received message from %s: %s\n", ctr.Role, ctr.Content)
			}
		}

		// Print any remaining message
		if currentMessage.Len() > 0 {
			fmt.Printf("\n\n[ConversationTextResponse]\n")
			fmt.Printf("%s: %s\n\n", currentSpeaker, currentMessage.String())

			// Write to chat log
			if err := dch.writeToChatLog(currentSpeaker, currentMessage.String()); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle user started speaking
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for range dch.userStartedSpeakingResponse {
			fmt.Printf("\n\n[UserStartedSpeakingResponse]\n")
			fmt.Printf("User has started speaking, waiting for completion...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", "User has started speaking"); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle agent thinking
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for atr := range dch.agentThinkingResponse {
			fmt.Printf("\n\n[AgentThinkingResponse]\n")
			fmt.Printf("Agent is processing input: %s\n", atr.Content)
			fmt.Printf("Waiting for agent's response...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", fmt.Sprintf("Agent is processing: %s", atr.Content)); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle agent started speaking
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for asr := range dch.agentStartedSpeakingResponse {
			fmt.Printf("\n\n[AgentStartedSpeakingResponse]\n")
			fmt.Printf("Agent is starting to respond (latency: %.2fms)\n", asr.TotalLatency)
			fmt.Printf("Processing agent's response...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", "Agent is starting to respond"); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle agent audio done
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for range dch.agentAudioDoneResponse {
			fmt.Printf("\n\n[AgentAudioDoneResponse]\n")
			fmt.Printf("Agent finished speaking, waiting for next user input...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", "Agent finished speaking"); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle keep alive responses
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()

		for range dch.keepAliveResponse {
			fmt.Printf("\n\n[KeepAliveResponse]\n")
			fmt.Printf("Connection is alive, waiting for next event...\n\n")

			// Write to chat log
			if err := dch.writeToChatLog("system", "Keep alive received"); err != nil {
				fmt.Printf("Failed to write to chat log: %v\n", err)
			}
		}
	}()

	// Handle other events
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for range dch.openChan {
			fmt.Printf("\n\n[OpenResponse]\n\n")
		}
	}()

	// welcome channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for range dch.welcomeResponse {
			fmt.Printf("\n\n[WelcomeResponse]\n\n")
		}
	}()

	// settings applied channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for range dch.settingsAppliedResponse {
			fmt.Printf("\n\n[SettingsAppliedResponse]\n\n")
		}
	}()

	// close channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for closeResp := range dch.closeChan {
			fmt.Printf("\n\n[CloseResponse]\n")
			fmt.Printf(" Close response received\n")
			fmt.Printf(" Close response type: %+v\n", closeResp)
			fmt.Printf("\n")
		}
	}()

	// error channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for er := range dch.errorChan {
			fmt.Printf("\n[ErrorResponse]\n")
			fmt.Printf("\nError.Type: %s\n", er.ErrCode)
			fmt.Printf("Error.Message: %s\n", er.ErrMsg)
			fmt.Printf("Error.Description: %s\n\n", er.Description)
			fmt.Printf("Error.Variant: %s\n\n", er.Variant)
		}
	}()

	// unhandled event channel
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for byData := range dch.unhandledChan {
			fmt.Printf("\n[UnhandledEvent]\n")
			fmt.Printf("Raw message: %s\n", string(*byData))
		}
	}()

	// Handle function call request
	wgReceivers.Add(1)
	go func() {
		defer wgReceivers.Done()
		for range dch.functionCallRequestResponse {
			fmt.Printf("\n\n[FunctionCallRequestResponse]\n\n")
		}
	}()

	// Wait for all receivers to finish
	wgReceivers.Wait()
	return nil
}

// Helper function to write to chat log
func (dch *MyHandler) writeToChatLog(role, content string) error {
	if dch.chatLogFile == nil {
		return fmt.Errorf("chat log file not initialized")
	}

	timestamp := time.Now().Format("2006-01-02 15:04:05")
	logEntry := fmt.Sprintf("[%s] %s: %s\n", timestamp, role, content)

	_, err := dch.chatLogFile.WriteString(logEntry)
	if err != nil {
		return fmt.Errorf("failed to write to chat log: %v", err)
	}

	return nil
}

// Main function
func main() {
	fmt.Printf(" Program starting\n")
	// Print instructions
	fmt.Print("\n\nPress ENTER to exit!\n\n")

	// Initialize context
	ctx := context.Background()
	fmt.Printf(" Context initialized\n")

	// Configure agent
	cOptions := configureAgent()
	fmt.Printf(" Agent configured\n")

	// Set transcription options
	tOptions := client.NewSettingsConfigurationOptions()
	tOptions.Audio.Input.Encoding = "linear16"
	tOptions.Audio.Input.SampleRate = 48000
	tOptions.Agent.Think.Provider.Type = "open_ai"
	tOptions.Agent.Think.Provider.Model = "gpt-4o-mini"
	tOptions.Agent.Think.Prompt = "You are a helpful AI assistant."
	tOptions.Agent.Listen.Provider.Type = "deepgram"
	tOptions.Agent.Listen.Provider.Model = "nova-3"
	tOptions.Agent.Speak.Provider.Type = "deepgram"
	tOptions.Agent.Speak.Provider.Model = "aura-2-thalia-en"
	tOptions.Agent.Language = "en"
	tOptions.Agent.Greeting = "Hello! How can I help you today?"
	fmt.Printf(" Transcription options set\n")

	// Create handler
	fmt.Printf("Creating new Deepgram WebSocket client...\n")
	handler := NewMyHandler()
	if handler == nil {
		fmt.Printf("Failed to create handler\n")
		return
	}
	fmt.Printf(" Handler created\n")
	defer handler.chatLogFile.Close()

	// Create client
	callback := msginterfaces.AgentMessageChan(*handler)
	fmt.Printf(" Callback created\n")
	dgClient, err := client.NewWSUsingChan(ctx, "", cOptions, tOptions, callback)
	if err != nil {
		fmt.Printf("ERROR creating LiveTranscription connection:\n- Error: %v\n- Type: %T\n", err, err)
		return
	}
	fmt.Printf(" Deepgram client created\n")

	// Connect to Deepgram
	fmt.Printf("Attempting to connect to Deepgram WebSocket...\n")
	bConnected := dgClient.Connect()
	if !bConnected {
		fmt.Printf("WebSocket connection failed - check your API key and network connection\n")
		os.Exit(1)
	}
	fmt.Printf(" Successfully connected to Deepgram WebSocket\n")

	// Stream audio from URL
	audioURL := "https://dpgr.am/spacewalk.wav"
	httpClient := new(http.Client)
	resp, err := httpClient.Get(audioURL)
	if err != nil {
		fmt.Printf("Failed to fetch audio from URL. Err: %v\n", err)
		return
	}
	fmt.Printf(" Audio URL fetched, content length: %d bytes\n", resp.ContentLength)
	fmt.Printf("Stream is up and running %s\n", reflect.TypeOf(resp))
	buf := bufio.NewReaderSize(resp.Body, 960*200) // Increase buffer to handle 200 chunks at once
	go func() {
		fmt.Printf(" Starting audio stream goroutine\n")
		fmt.Printf("Starting to stream audio from URL...\n")
		defer resp.Body.Close()
		err = dgClient.Stream(buf)
		if err != nil && err != io.EOF {
			fmt.Printf("Failed to stream audio. Err: %v\n", err)
			return
		}
		fmt.Printf(" Audio stream completed\n")
		fmt.Printf("Finished streaming audio from URL\n")
	}()

	// Wait for user input to exit
	fmt.Printf(" Waiting for user input\n")
	input := bufio.NewScanner(os.Stdin)
	input.Scan()
	fmt.Printf(" User input received\n")

	// Cleanup
	fmt.Printf(" Starting cleanup sequence...\n")
	fmt.Printf(" Calling dgClient.Stop()\n")
	dgClient.Stop()
	fmt.Printf(" dgClient.Stop() completed\n")
	fmt.Printf("\n\nProgram exiting...\n")
}
  ```
</CodeGroup>

## Implementation Examples

To better understand how to build a more complex Voice Agent, check out the following examples for working code.

| Use Case                                                                    | Runtime / Language           | Repo                                                                                                                                          |
| --------------------------------------------------------------------------- | ---------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| Voice agent basic demo   | Node, TypeScript, JavaScript | [Deepgram Voice Agent Demo](https://github.com/deepgram-devs/deepgram-voice-agent-demo)                                                       |
| Voice agent medical assistant demo                                                    | Node, TypeScript, JavaScript        | [Deepgram Voice Agent Medical Assistant Demo](https://github.com/deepgram-devs/voice-agent-medical-assistant-demo)
| Voice agent demo with Twilio                              | Python                       | [Python Twilio > Voice Agent Demo](/docs/twilio-and-deepgram-voice-agent)                                                                     |
| Voice agent demo with text input    | Node, TypeScript, JavaScript | [Deepgram Conversational AI Demo](https://github.com/deepgram-devs/deepgram-ai-agent-demo)                                                    |
| Voice agent with Azure Open AI Services | Python                       | [Deepgram Voice Agent with OpenAI Azure](https://github.com/deepgram-devs/voice-agent-azure-open-ai-services)                                 |
| Voice agent with Function Calling using Python Flask          | Python / Flask               | [Python Flask Agent Function Calling Demo](https://github.com/deepgram-devs/flask-agent-function-calling-demo)                                |
                                  |


## Rate Limits

<Info>
  For information on Deepgram's Concurrency Rate Limits, refer to our [API Rate Limits Documentation](/reference/api-rate-limits).
</Info>

## Usage Tracking

Usage is calculated based on websocket connection time. 1 hour of websocket connection time = 1 hour of API usage.

